{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST-ANN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "oI4gb4BXhoy7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Problem DefinitionÂ¶**\n",
        "\n",
        "*   How to recognize handwritten digits\n",
        "\n",
        "\n",
        "\n",
        "## **Data**\n",
        "\n",
        "The MNIST database (link) has a database of handwritten digits.\n",
        "\n",
        "The training set has 60K samples. The test set has 10K samples.\n",
        "\n",
        "The digits are size-normalized and centered in a fixed-size image.\n",
        "\n",
        "## **Load the data**\n",
        "\n",
        "The data is available in the repo's data folder. Let's load that using the keras library. For now, let's load the data and see how it looks.\n",
        "\n",
        "We will look into keras a little while later."
      ]
    },
    {
      "metadata": {
        "id": "zgZky2vHeZCj",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7Ci8vIE1heCBhbW91bnQgb2YgdGltZSB0byBibG9jayB3YWl0aW5nIGZvciB0aGUgdXNlci4KY29uc3QgRklMRV9DSEFOR0VfVElNRU9VVF9NUyA9IDMwICogMTAwMDsKCmZ1bmN0aW9uIF91cGxvYWRGaWxlcyhpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IHN0ZXBzID0gdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKTsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIC8vIENhY2hlIHN0ZXBzIG9uIHRoZSBvdXRwdXRFbGVtZW50IHRvIG1ha2UgaXQgYXZhaWxhYmxlIGZvciB0aGUgbmV4dCBjYWxsCiAgLy8gdG8gdXBsb2FkRmlsZXNDb250aW51ZSBmcm9tIFB5dGhvbi4KICBvdXRwdXRFbGVtZW50LnN0ZXBzID0gc3RlcHM7CgogIHJldHVybiBfdXBsb2FkRmlsZXNDb250aW51ZShvdXRwdXRJZCk7Cn0KCi8vIFRoaXMgaXMgcm91Z2hseSBhbiBhc3luYyBnZW5lcmF0b3IgKG5vdCBzdXBwb3J0ZWQgaW4gdGhlIGJyb3dzZXIgeWV0KSwKLy8gd2hlcmUgdGhlcmUgYXJlIG11bHRpcGxlIGFzeW5jaHJvbm91cyBzdGVwcyBhbmQgdGhlIFB5dGhvbiBzaWRlIGlzIGdvaW5nCi8vIHRvIHBvbGwgZm9yIGNvbXBsZXRpb24gb2YgZWFjaCBzdGVwLgovLyBUaGlzIHVzZXMgYSBQcm9taXNlIHRvIGJsb2NrIHRoZSBweXRob24gc2lkZSBvbiBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcCwKLy8gdGhlbiBwYXNzZXMgdGhlIHJlc3VsdCBvZiB0aGUgcHJldmlvdXMgc3RlcCBhcyB0aGUgaW5wdXQgdG8gdGhlIG5leHQgc3RlcC4KZnVuY3Rpb24gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpIHsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIGNvbnN0IHN0ZXBzID0gb3V0cHV0RWxlbWVudC5zdGVwczsKCiAgY29uc3QgbmV4dCA9IHN0ZXBzLm5leHQob3V0cHV0RWxlbWVudC5sYXN0UHJvbWlzZVZhbHVlKTsKICByZXR1cm4gUHJvbWlzZS5yZXNvbHZlKG5leHQudmFsdWUucHJvbWlzZSkudGhlbigodmFsdWUpID0+IHsKICAgIC8vIENhY2hlIHRoZSBsYXN0IHByb21pc2UgdmFsdWUgdG8gbWFrZSBpdCBhdmFpbGFibGUgdG8gdGhlIG5leHQKICAgIC8vIHN0ZXAgb2YgdGhlIGdlbmVyYXRvci4KICAgIG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSA9IHZhbHVlOwogICAgcmV0dXJuIG5leHQudmFsdWUucmVzcG9uc2U7CiAgfSk7Cn0KCi8qKgogKiBHZW5lcmF0b3IgZnVuY3Rpb24gd2hpY2ggaXMgY2FsbGVkIGJldHdlZW4gZWFjaCBhc3luYyBzdGVwIG9mIHRoZSB1cGxvYWQKICogcHJvY2Vzcy4KICogQHBhcmFtIHtzdHJpbmd9IGlucHV0SWQgRWxlbWVudCBJRCBvZiB0aGUgaW5wdXQgZmlsZSBwaWNrZXIgZWxlbWVudC4KICogQHBhcmFtIHtzdHJpbmd9IG91dHB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIG91dHB1dCBkaXNwbGF5LgogKiBAcmV0dXJuIHshSXRlcmFibGU8IU9iamVjdD59IEl0ZXJhYmxlIG9mIG5leHQgc3RlcHMuCiAqLwpmdW5jdGlvbiogdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKSB7CiAgY29uc3QgaW5wdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQoaW5wdXRJZCk7CiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gZmFsc2U7CgogIGNvbnN0IG91dHB1dEVsZW1lbnQgPSBkb2N1bWVudC5nZXRFbGVtZW50QnlJZChvdXRwdXRJZCk7CiAgb3V0cHV0RWxlbWVudC5pbm5lckhUTUwgPSAnJzsKCiAgY29uc3QgcGlja2VkUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBpbnB1dEVsZW1lbnQuYWRkRXZlbnRMaXN0ZW5lcignY2hhbmdlJywgKGUpID0+IHsKICAgICAgcmVzb2x2ZShlLnRhcmdldC5maWxlcyk7CiAgICB9KTsKICB9KTsKCiAgY29uc3QgY2FuY2VsID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnYnV0dG9uJyk7CiAgaW5wdXRFbGVtZW50LnBhcmVudEVsZW1lbnQuYXBwZW5kQ2hpbGQoY2FuY2VsKTsKICBjYW5jZWwudGV4dENvbnRlbnQgPSAnQ2FuY2VsIHVwbG9hZCc7CiAgY29uc3QgY2FuY2VsUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBjYW5jZWwub25jbGljayA9ICgpID0+IHsKICAgICAgcmVzb2x2ZShudWxsKTsKICAgIH07CiAgfSk7CgogIC8vIENhbmNlbCB1cGxvYWQgaWYgdXNlciBoYXNuJ3QgcGlja2VkIGFueXRoaW5nIGluIHRpbWVvdXQuCiAgY29uc3QgdGltZW91dFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgc2V0VGltZW91dCgoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9LCBGSUxFX0NIQU5HRV9USU1FT1VUX01TKTsKICB9KTsKCiAgLy8gV2FpdCBmb3IgdGhlIHVzZXIgdG8gcGljayB0aGUgZmlsZXMuCiAgY29uc3QgZmlsZXMgPSB5aWVsZCB7CiAgICBwcm9taXNlOiBQcm9taXNlLnJhY2UoW3BpY2tlZFByb21pc2UsIHRpbWVvdXRQcm9taXNlLCBjYW5jZWxQcm9taXNlXSksCiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdzdGFydGluZycsCiAgICB9CiAgfTsKCiAgaWYgKCFmaWxlcykgewogICAgcmV0dXJuIHsKICAgICAgcmVzcG9uc2U6IHsKICAgICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICAgIH0KICAgIH07CiAgfQoKICBjYW5jZWwucmVtb3ZlKCk7CgogIC8vIERpc2FibGUgdGhlIGlucHV0IGVsZW1lbnQgc2luY2UgZnVydGhlciBwaWNrcyBhcmUgbm90IGFsbG93ZWQuCiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gdHJ1ZTsKCiAgZm9yIChjb25zdCBmaWxlIG9mIGZpbGVzKSB7CiAgICBjb25zdCBsaSA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2xpJyk7CiAgICBsaS5hcHBlbmQoc3BhbihmaWxlLm5hbWUsIHtmb250V2VpZ2h0OiAnYm9sZCd9KSk7CiAgICBsaS5hcHBlbmQoc3BhbigKICAgICAgICBgKCR7ZmlsZS50eXBlIHx8ICduL2EnfSkgLSAke2ZpbGUuc2l6ZX0gYnl0ZXMsIGAgKwogICAgICAgIGBsYXN0IG1vZGlmaWVkOiAkewogICAgICAgICAgICBmaWxlLmxhc3RNb2RpZmllZERhdGUgPyBmaWxlLmxhc3RNb2RpZmllZERhdGUudG9Mb2NhbGVEYXRlU3RyaW5nKCkgOgogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAnbi9hJ30gLSBgKSk7CiAgICBjb25zdCBwZXJjZW50ID0gc3BhbignMCUgZG9uZScpOwogICAgbGkuYXBwZW5kQ2hpbGQocGVyY2VudCk7CgogICAgb3V0cHV0RWxlbWVudC5hcHBlbmRDaGlsZChsaSk7CgogICAgY29uc3QgZmlsZURhdGFQcm9taXNlID0gbmV3IFByb21pc2UoKHJlc29sdmUpID0+IHsKICAgICAgY29uc3QgcmVhZGVyID0gbmV3IEZpbGVSZWFkZXIoKTsKICAgICAgcmVhZGVyLm9ubG9hZCA9IChlKSA9PiB7CiAgICAgICAgcmVzb2x2ZShlLnRhcmdldC5yZXN1bHQpOwogICAgICB9OwogICAgICByZWFkZXIucmVhZEFzQXJyYXlCdWZmZXIoZmlsZSk7CiAgICB9KTsKICAgIC8vIFdhaXQgZm9yIHRoZSBkYXRhIHRvIGJlIHJlYWR5LgogICAgbGV0IGZpbGVEYXRhID0geWllbGQgewogICAgICBwcm9taXNlOiBmaWxlRGF0YVByb21pc2UsCiAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgYWN0aW9uOiAnY29udGludWUnLAogICAgICB9CiAgICB9OwoKICAgIC8vIFVzZSBhIGNodW5rZWQgc2VuZGluZyB0byBhdm9pZCBtZXNzYWdlIHNpemUgbGltaXRzLiBTZWUgYi82MjExNTY2MC4KICAgIGxldCBwb3NpdGlvbiA9IDA7CiAgICB3aGlsZSAocG9zaXRpb24gPCBmaWxlRGF0YS5ieXRlTGVuZ3RoKSB7CiAgICAgIGNvbnN0IGxlbmd0aCA9IE1hdGgubWluKGZpbGVEYXRhLmJ5dGVMZW5ndGggLSBwb3NpdGlvbiwgTUFYX1BBWUxPQURfU0laRSk7CiAgICAgIGNvbnN0IGNodW5rID0gbmV3IFVpbnQ4QXJyYXkoZmlsZURhdGEsIHBvc2l0aW9uLCBsZW5ndGgpOwogICAgICBwb3NpdGlvbiArPSBsZW5ndGg7CgogICAgICBjb25zdCBiYXNlNjQgPSBidG9hKFN0cmluZy5mcm9tQ2hhckNvZGUuYXBwbHkobnVsbCwgY2h1bmspKTsKICAgICAgeWllbGQgewogICAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgICBhY3Rpb246ICdhcHBlbmQnLAogICAgICAgICAgZmlsZTogZmlsZS5uYW1lLAogICAgICAgICAgZGF0YTogYmFzZTY0LAogICAgICAgIH0sCiAgICAgIH07CiAgICAgIHBlcmNlbnQudGV4dENvbnRlbnQgPQogICAgICAgICAgYCR7TWF0aC5yb3VuZCgocG9zaXRpb24gLyBmaWxlRGF0YS5ieXRlTGVuZ3RoKSAqIDEwMCl9JSBkb25lYDsKICAgIH0KICB9CgogIC8vIEFsbCBkb25lLgogIHlpZWxkIHsKICAgIHJlc3BvbnNlOiB7CiAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgIH0KICB9Owp9CgpzY29wZS5nb29nbGUgPSBzY29wZS5nb29nbGUgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYiA9IHNjb3BlLmdvb2dsZS5jb2xhYiB8fCB7fTsKc2NvcGUuZ29vZ2xlLmNvbGFiLl9maWxlcyA9IHsKICBfdXBsb2FkRmlsZXMsCiAgX3VwbG9hZEZpbGVzQ29udGludWUsCn07Cn0pKHNlbGYpOwo=",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "fa81d5e8-2ce9-4987-bc10-f86fed84d27c"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b38af002-e768-48f2-88be-528030e9ec33\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-b38af002-e768-48f2-88be-528030e9ec33\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving mnist.pkl.gz to mnist.pkl.gz\n",
            "User uploaded file \"mnist.pkl.gz\" with length 11490434 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "s_geY-Tke4E-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m_lrT1TyfXe9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Set the full path to mnist.pkl.gz\n",
        "# Point this to the data folder inside the repository\n",
        "path_to_dataset = \"mnist.pkl.gz\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6TgopOIwfce6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load the datasets\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data(path_to_dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TpAn-oJeffAp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3fc13ca0-280e-47ec-ab94-27f6161cb0f4"
      },
      "cell_type": "code",
      "source": [
        "# What is the type of X_train?\n",
        "type(X_train)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "metadata": {
        "id": "L5tDeUSMfj-j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2f52948d-2014-42dd-8684-228b8636ae1d"
      },
      "cell_type": "code",
      "source": [
        "# What is the type of y_train #\n",
        "type(y_train)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "metadata": {
        "id": "sC4C12gTfl-T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "28a9ea7b-4606-440f-f557-4a3b03cffd95"
      },
      "cell_type": "code",
      "source": [
        "# Find number of observations in training data\n",
        "len(X_train)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "metadata": {
        "id": "Rk7hUb-vfnnE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "96fd4011-4e7c-47ab-9f91-591ea4ddab58"
      },
      "cell_type": "code",
      "source": [
        "# Find number of observations in test data\n",
        "len(X_test)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "metadata": {
        "id": "zJpAxBxHfphM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "31ab0699-03cf-46af-a478-4380b4d5b068"
      },
      "cell_type": "code",
      "source": [
        "# Display first 2 records of X_train\n",
        "print(X_train[0:2,])"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  ...\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]]\n",
            "\n",
            " [[0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  ...\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "K542F3_eftro",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c72608a9-082c-4cd5-b20c-f5aaacaf926e"
      },
      "cell_type": "code",
      "source": [
        "# Display the first 10 records of y_train\n",
        "y_train[0:10,]\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "metadata": {
        "id": "H4YGlfk7gRzb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ccb2c6b1-1978-4c90-c14b-2971f5b8f957"
      },
      "cell_type": "code",
      "source": [
        "print(y_train.shape)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UK66DG0agT3M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "5664d0ab-9777-4b16-ee81-2b7dfd1390f5"
      },
      "cell_type": "code",
      "source": [
        "# Find the number of observations for digits 2 & 3 in the y_train dataset \n",
        "print(len(y_train[np.where(y_train == 2.)[0]]))\n",
        "print(len(y_train[np.where(y_train == 3.)[0]]))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5958\n",
            "6131\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "C147i1XvgbuP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "map_output = map(lambda x: x*2, [1, 2, 3, 4])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xab3uaDugdW2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "14c53850-92d7-4f87-a1b6-3651596ac22e"
      },
      "cell_type": "code",
      "source": [
        "# Find the number of observations for digits 2 & 3 in the y_test dataset \n",
        "print(len(y_test[np.where(y_test == 2.)[0]]))\n",
        "print(len(y_test[np.where(y_test == 3.)[0]]))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1032\n",
            "1010\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OTgnEzYSggVp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b4e9fa3c-45a6-46b9-90bb-5b5df09757ef"
      },
      "cell_type": "code",
      "source": [
        "# What is the dimension of X_train?. What does that mean?\n",
        "X_train.shape"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "metadata": {
        "id": "CPOz7izqg77Y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Display Images**\n",
        "\n",
        "Let's now display some of the images and see how they look\n",
        "\n",
        "We will be using matplotlib library for displaying the image"
      ]
    },
    {
      "metadata": {
        "id": "60ag99dwhPaj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot\n",
        "import matplotlib as mpl\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MZmFhzlhgo8Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "3e923526-89a6-4957-ad33-f741e1eb0325"
      },
      "cell_type": "code",
      "source": [
        "# Displaying the first training data\n",
        "fig = pyplot.figure()\n",
        "ax = fig.add_subplot(1,1,1)\n",
        "imgplot = ax.imshow(X_train[1], cmap=mpl.cm.Greys)\n",
        "imgplot.set_interpolation('nearest')\n",
        "ax.xaxis.set_ticks_position('top')\n",
        "ax.yaxis.set_ticks_position('left')\n",
        "pyplot.show()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD4CAYAAADFJPs2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f0b21bb9a20>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "7WUcLfxfhKN4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "746f5776-3369-4a25-b01c-1ee3531d01f9"
      },
      "cell_type": "code",
      "source": [
        "# Let's now display the 5th record\n",
        "fig = pyplot.figure()\n",
        "ax = fig.add_subplot(1,1,1)\n",
        "imgplot = ax.imshow(X_train[5], cmap=mpl.cm.Greys)\n",
        "imgplot.set_interpolation('nearest')\n",
        "ax.xaxis.set_ticks_position('top')\n",
        "ax.yaxis.set_ticks_position('left')\n",
        "pyplot.show()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD4CAYAAADFJPs2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nf87Aaf6goXCgAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f0b216ba390>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "3fhWaHimhb2Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f20fe93a-5a49-4f8e-a047-d0574c3ef5e0"
      },
      "cell_type": "code",
      "source": [
        "!ls\n"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mnist.pkl.gz\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "T6Gihopgkruq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Implementing ANN for MNIST**\n",
        "\n",
        "Code Courtesy : Nielsen (Author - NeuralNetworksandDeepLearning)"
      ]
    },
    {
      "metadata": {
        "id": "9yk5K48iigJA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import random\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RmAulTH2mmZA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Set the full path to mnist.pkl.gz\n",
        "# Point this to the data folder inside the repository\n",
        "path_to_dataset = \"mnist.pkl.gz\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pPO0IvSFmn55",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load the datasets\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data(path_to_dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wjyegABBmpgQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "network.py\n",
        "~~~~~~~~~~\n",
        "A module to implement the stochastic gradient descent learning\n",
        "algorithm for a feedforward neural network.  Gradients are calculated\n",
        "using backpropagation.  Note that I have focused on making the code\n",
        "simple, easily readable, and easily modifiable.  It is not optimized,\n",
        "and omits many desirable features.\n",
        "\"\"\"\n",
        "\n",
        "#### Libraries\n",
        "# Standard library\n",
        "import random\n",
        "\n",
        "# Third-party libraries\n",
        "import numpy as np\n",
        "\n",
        "class Network(object):\n",
        "\n",
        "    def __init__(self, sizes):\n",
        "        \"\"\"The list ``sizes`` contains the number of neurons in the\n",
        "        respective layers of the network.  For example, if the list\n",
        "        was [2, 3, 1] then it would be a three-layer network, with the\n",
        "        first layer containing 2 neurons, the second layer 3 neurons,\n",
        "        and the third layer 1 neuron.  The biases and weights for the\n",
        "        network are initialized randomly, using a Gaussian\n",
        "        distribution with mean 0, and variance 1.  Note that the first\n",
        "        layer is assumed to be an input layer, and by convention we\n",
        "        won't set any biases for those neurons, since biases are only\n",
        "        ever used in computing the outputs from later layers.\"\"\"\n",
        "        self.num_layers = len(sizes)\n",
        "        self.sizes = sizes\n",
        "        self.biases = [np.random.randn(y, 1) for y in sizes[1:]]\n",
        "        self.weights = [np.random.randn(y, x)\n",
        "                        for x, y in zip(sizes[:-1], sizes[1:])]\n",
        "\n",
        "    def feedforward(self, a):\n",
        "        \"\"\"Return the output of the network if ``a`` is input.\"\"\"\n",
        "        for b, w in zip(self.biases, self.weights):\n",
        "            a = sigmoid(np.dot(w, a)+b)\n",
        "        return a\n",
        "\n",
        "    def SGD(self, training_data, epochs, mini_batch_size, eta,\n",
        "            test_data=None):\n",
        "        \"\"\"Train the neural network using mini-batch stochastic\n",
        "        gradient descent.  The ``training_data`` is a list of tuples\n",
        "        ``(x, y)`` representing the training inputs and the desired\n",
        "        outputs.  The other non-optional parameters are\n",
        "        self-explanatory.  If ``test_data`` is provided then the\n",
        "        network will be evaluated against the test data after each\n",
        "        epoch, and partial progress printed out.  This is useful for\n",
        "        tracking progress, but slows things down substantially.\"\"\"\n",
        "        training_data = list(training_data)\n",
        "        test_data = list(test_data)\n",
        "        if test_data: n_test = len(test_data)\n",
        "        n = len(training_data)\n",
        "        for j in range(epochs):\n",
        "            random.shuffle(training_data)\n",
        "            mini_batches = [\n",
        "                training_data[k:k+mini_batch_size]\n",
        "                for k in range(0, n, mini_batch_size)]\n",
        "            for mini_batch in mini_batches:\n",
        "                self.update_mini_batch(mini_batch, eta)\n",
        "            if test_data:\n",
        "                print( \"Epoch {0}: {1} / {2}\".format(\n",
        "                    j, self.evaluate(test_data), n_test))\n",
        "            else:\n",
        "                print( \"Epoch {0} complete\".format(j))\n",
        "\n",
        "    def update_mini_batch(self, mini_batch, eta):\n",
        "        \"\"\"Update the network's weights and biases by applying\n",
        "        gradient descent using backpropagation to a single mini batch.\n",
        "        The ``mini_batch`` is a list of tuples ``(x, y)``, and ``eta``\n",
        "        is the learning rate.\"\"\"\n",
        "        nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
        "        nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
        "        for x, y in mini_batch:\n",
        "            delta_nabla_b, delta_nabla_w = self.backprop(x, y)\n",
        "            nabla_b = [nb+dnb for nb, dnb in zip(nabla_b, delta_nabla_b)]\n",
        "            nabla_w = [nw+dnw for nw, dnw in zip(nabla_w, delta_nabla_w)]\n",
        "        self.weights = [w-(eta/len(mini_batch))*nw\n",
        "                        for w, nw in zip(self.weights, nabla_w)]\n",
        "        self.biases = [b-(eta/len(mini_batch))*nb\n",
        "                       for b, nb in zip(self.biases, nabla_b)]\n",
        "\n",
        "    def backprop(self, x, y):\n",
        "        \"\"\"Return a tuple ``(nabla_b, nabla_w)`` representing the\n",
        "        gradient for the cost function C_x.  ``nabla_b`` and\n",
        "        ``nabla_w`` are layer-by-layer lists of numpy arrays, similar\n",
        "        to ``self.biases`` and ``self.weights``.\"\"\"\n",
        "        nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
        "        nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
        "        # feedforward\n",
        "        activation = x\n",
        "        activations = [x] # list to store all the activations, layer by layer\n",
        "        zs = [] # list to store all the z vectors, layer by layer\n",
        "        for b, w in zip(self.biases, self.weights):\n",
        "            z = np.dot(w, activation)+b\n",
        "            zs.append(z)\n",
        "            activation = sigmoid(z)\n",
        "            activations.append(activation)\n",
        "        # backward pass\n",
        "        delta = self.cost_derivative(activations[-1], y) * \\\n",
        "            sigmoid_prime(zs[-1])\n",
        "        nabla_b[-1] = delta\n",
        "        nabla_w[-1] = np.dot(delta, activations[-2].transpose())\n",
        "        # Note that the variable l in the loop below is used a little\n",
        "        # differently to the notation in Chapter 2 of the book.  Here,\n",
        "        # l = 1 means the last layer of neurons, l = 2 is the\n",
        "        # second-last layer, and so on.  It's a renumbering of the\n",
        "        # scheme in the book, used here to take advantage of the fact\n",
        "        # that Python can use negative indices in lists.\n",
        "        for l in range(2, self.num_layers):\n",
        "            z = zs[-l]\n",
        "            sp = sigmoid_prime(z)\n",
        "            delta = np.dot(self.weights[-l+1].transpose(), delta) * sp\n",
        "            nabla_b[-l] = delta\n",
        "            nabla_w[-l] = np.dot(delta, activations[-l-1].transpose())\n",
        "        return (nabla_b, nabla_w)\n",
        "\n",
        "    def evaluate(self, test_data):\n",
        "        \"\"\"Return the number of test inputs for which the neural\n",
        "        network outputs the correct result. Note that the neural\n",
        "        network's output is assumed to be the index of whichever\n",
        "        neuron in the final layer has the highest activation.\"\"\"\n",
        "        test_results = [(np.argmax(self.feedforward(x)), y)\n",
        "                        for (x, y) in test_data]\n",
        "        return sum(int(x == y) for (x, y) in test_results)\n",
        "\n",
        "    def cost_derivative(self, output_activations, y):\n",
        "        \"\"\"Return the vector of partial derivatives \\partial C_x /\n",
        "        \\partial a for the output activations.\"\"\"\n",
        "        return (output_activations-y)\n",
        "\n",
        "#### Miscellaneous functions\n",
        "def sigmoid(z):\n",
        "    \"\"\"The sigmoid function.\"\"\"\n",
        "    return 1.0/(1.0+np.exp(-z))\n",
        "\n",
        "def sigmoid_prime(z):\n",
        "    \"\"\"Derivative of the sigmoid function.\"\"\"\n",
        "    return sigmoid(z)*(1-sigmoid(z))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XhpLhGlVmtEr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def vectorized_result(j):\n",
        "    \"\"\"Return a 10-dimensional unit vector with a 1.0 in the jth\n",
        "    position and zeroes elsewhere.  This is used to convert a digit\n",
        "    (0...9) into a corresponding desired output from the neural\n",
        "    network.\"\"\"\n",
        "    e = np.zeros((10, 1))\n",
        "    e[j] = 1.0\n",
        "    return e"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Exn3MnmumvAR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "net = Network([784, 30, 10])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3_hQo7dXmwaW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "training_inputs = [np.reshape(x, (784, 1)) for x in X_train.copy()]\n",
        "training_results = [vectorized_result(y) for y in y_train.copy()]\n",
        "training_data = zip(training_inputs, training_results)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aKDMHJ7gmyDx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_inputs = [np.reshape(x, (784, 1)) for x in X_test.copy()]\n",
        "test_data = zip(test_inputs, y_test.copy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QBAEGVtcmzjg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "588c1e52-299d-49ed-933f-3be1725b67ff"
      },
      "cell_type": "code",
      "source": [
        "net.SGD(training_data, 10, 10, 3.0, test_data=test_data)\n"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:137: RuntimeWarning: overflow encountered in exp\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0: 2847 / 10000\n",
            "Epoch 1: 2378 / 10000\n",
            "Epoch 2: 2766 / 10000\n",
            "Epoch 3: 3012 / 10000\n",
            "Epoch 4: 3407 / 10000\n",
            "Epoch 5: 3012 / 10000\n",
            "Epoch 6: 3224 / 10000\n",
            "Epoch 7: 1952 / 10000\n",
            "Epoch 8: 2056 / 10000\n",
            "Epoch 9: 2125 / 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Z5gx0IMmm11i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "0208a742-696a-44dc-85af-ddadc7f9b24e"
      },
      "cell_type": "code",
      "source": [
        "net = Network([784, 10, 10])\n",
        "\n",
        "training_inputs = [np.reshape(x, (784, 1)) for x in X_train.copy()]\n",
        "training_results = [vectorized_result(y) for y in y_train.copy()]\n",
        "training_data = zip(training_inputs, training_results)\n",
        "\n",
        "test_inputs = [np.reshape(x, (784, 1)) for x in X_test.copy()]\n",
        "test_data = zip(test_inputs, y_test.copy())\n",
        "\n",
        "net.SGD(training_data, 10, 10, 1.0, test_data=test_data)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:137: RuntimeWarning: overflow encountered in exp\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0: 1918 / 10000\n",
            "Epoch 1: 1664 / 10000\n",
            "Epoch 2: 1985 / 10000\n",
            "Epoch 3: 2080 / 10000\n",
            "Epoch 4: 1984 / 10000\n",
            "Epoch 5: 1889 / 10000\n",
            "Epoch 6: 2111 / 10000\n",
            "Epoch 7: 2013 / 10000\n",
            "Epoch 8: 1857 / 10000\n",
            "Epoch 9: 2038 / 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "y7qLXdqxnJ2B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b9aaca0a-f6e5-45f8-fdca-d1038152793b"
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mnist.pkl.gz\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ptXOj2vqozXb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}