{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution Neural Network for MNIST\n",
    "\n",
    "Deep Learning models can take quite a bit of time to run, particularly if GPU isn't used. \n",
    "In the interest of time, we will sample fewer observations that are 7 and fewer observations that aren't 7. \n",
    "We will build a model using that and see how it performs on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the required libraries\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import SGD\n",
    "np.random.seed(1338)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = \"mnist.pkl.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the training and testing data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data(path_to_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols,1)\n",
    "X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols,1)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seed for reproducibilty\n",
    "np.random.seed(1338)\n",
    "\n",
    "#test data\n",
    "\n",
    "X_test = X_test.copy()\n",
    "Y = y_test.copy()\n",
    "#Converting the output to binary classification(Seven=1,Not Seven=0)\n",
    "Y_test = Y == 7\n",
    "Y_test = Y_test.astype(int)\n",
    "\n",
    "#Selecting the examples where the output is 7\n",
    "X_seven = X_train[y_train == 7].copy()\n",
    "Y_seven = y_train[y_train == 7].copy()\n",
    "#Selecting the examples where the output is not 7\n",
    "X_not_seven = X_train[y_train != 7].copy()\n",
    "Y_not_seven = y_train[y_train != 7].copy()\n",
    "\n",
    "#Selecting 6000 random examples from the data that contains only the data where the output is not 7\n",
    "random_rows = np.random.randint(0,X_seven.shape[0],6000)\n",
    "X_not_seven = X_not_seven[random_rows]\n",
    "Y_not_seven = Y_not_seven[random_rows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Appending the data with output as 7 and data with output as not 7\n",
    "X_train = np.append(X_seven,X_not_seven)\n",
    "#Reshaping the appended data to appropraite form\n",
    "X_train = X_train.reshape(X_seven.shape[0] + X_not_seven.shape[0], img_rows, img_cols,1)\n",
    "#Appending the labels and converting the labels to binary classification(seven=1,Not seven=0)\n",
    "Y_labels = np.append(Y_seven,Y_not_seven)\n",
    "Y_train = Y_labels == 7 \n",
    "Y_train = Y_train.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12265, 28, 28, 1) (12265,) (10000,) (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, Y_labels.shape, Y_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting the classes to its binary categorical form\n",
    "nb_classes = 2\n",
    "Y_train = np_utils.to_categorical(Y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(Y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A simple CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing the values for the convolution neural network\n",
    "nb_epoch = 2\n",
    "batch_size = 128\n",
    "# number of convolutional filters to use\n",
    "nb_filters = 32\n",
    "# size of pooling area for max pooling\n",
    "nb_pool = 2\n",
    "# convolution kernel size\n",
    "nb_conv = 3\n",
    "\n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.4_2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/models.py:942: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12265 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "12265/12265 [==============================] - 5s 389us/step - loss: 0.3213 - acc: 0.9232 - val_loss: 0.1651 - val_acc: 0.9570\n",
      "Epoch 2/2\n",
      "12265/12265 [==============================] - 5s 374us/step - loss: 0.1495 - acc: 0.9520 - val_loss: 0.1588 - val_acc: 0.9469\n",
      "Test score: 0.1588409436941147\n",
      "Test accuracy: 0.9469\n"
     ]
    }
   ],
   "source": [
    "input_shape = (img_rows, img_cols, 1)\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(5, 5), strides=(1, 1),\n",
    "                        activation='relu',\n",
    "                        input_shape=input_shape))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "    \n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.SGD(lr=0.01),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch,verbose=1,\n",
    "              validation_data=(X_test, Y_test))\n",
    "          \n",
    "\n",
    "#Evaluating the model on the test data    \n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding  dense layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.4_2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/models.py:942: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12265 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "12265/12265 [==============================] - 8s 653us/step - loss: 0.3015 - acc: 0.9172 - val_loss: 0.1686 - val_acc: 0.9491\n",
      "Epoch 2/2\n",
      "12265/12265 [==============================] - 7s 609us/step - loss: 0.1333 - acc: 0.9574 - val_loss: 0.1224 - val_acc: 0.9591\n",
      "Test score: 0.12240466742515564\n",
      "Test accuracy: 0.9591\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(5, 5), strides=(1, 1),\n",
    "                        activation='relu',\n",
    "                        input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "    \n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch,verbose=1,\n",
    "              validation_data=(X_test, Y_test))\n",
    "          \n",
    "\n",
    "#Evaluating the model on the test data    \n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding a dropout mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.4_2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/models.py:942: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12265 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "12265/12265 [==============================] - 8s 631us/step - loss: 0.2918 - acc: 0.9090 - val_loss: 0.1386 - val_acc: 0.9608\n",
      "Epoch 2/2\n",
      "12265/12265 [==============================] - 7s 608us/step - loss: 0.1447 - acc: 0.9528 - val_loss: 0.1115 - val_acc: 0.9646\n",
      "Test score: 0.11149236168563366\n",
      "Test accuracy: 0.9646\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(5, 5), strides=(1, 1),\n",
    "                        activation='relu',\n",
    "                        input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "    \n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch,verbose=1,\n",
    "              validation_data=(X_test, Y_test))\n",
    "          \n",
    "\n",
    "#Evaluating the model on the test data    \n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "\n",
    "Convert the above in to function. Move the hyperparameters as parameters to the function and see what happens. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function for constructing the convolution neural network\n",
    "def build_model():\n",
    "    .\n",
    "    .\n",
    "    .\n",
    "    .\n",
    "    .\n",
    "    .\n",
    "    .\n",
    "    .\n",
    "    \n",
    "    #Evaluating the model on the test data    \n",
    "    score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "    print('Test score:', score[0])\n",
    "    print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11918 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "11918/11918 [==============================] - 27s - loss: 0.2651 - acc: 0.8991 - val_loss: 0.1886 - val_acc: 0.9315\n",
      "Epoch 2/2\n",
      "11918/11918 [==============================] - 27s - loss: 0.1317 - acc: 0.9554 - val_loss: 0.1353 - val_acc: 0.9506\n",
      "Test score: 0.135310443386\n",
      "Test accuracy: 0.9506\n",
      "1 loop, best of 1: 1min 3s per loop\n"
     ]
    }
   ],
   "source": [
    "#Timing how long it takes to build the model and test it.\n",
    "%timeit -n1 -r1 build_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
